{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3096a4c-e118-46ae-8f07-47a09a0649b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - nvidia\n",
      " - conda-forge\n",
      " - pytorch\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 23.11.0\n",
      "    latest version: 25.3.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install cudatoolkit=11.8 -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eda69d-a3b2-448d-8575-8c2f3154e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "#  Neural Networks and Deep Learning Coursework - CIFAR-10 classification\n",
    "#  Student Name: Ka Yi Cheng\n",
    "#  Student id: 220566472\n",
    "#  Date: 11th April, 2025\n",
    "#  Reference Taken:\n",
    "#  JupyterHub/ECS659P-ECS7026P/ResNet_Answer.ipynb\n",
    "# -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c7174f3-91c5-4e69-8a2a-66bd3db50b9d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.utils.checkpoint import checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db8bfc5-0da5-4265-bca1-aa3c868c175a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device}.')\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3335692-6169-4eda-a7c4-2ac786220dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aa72632-b981-4f24-93d6-885d98b0f276",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "def load_data_cifar_10(batch_size, resize=None):\n",
    "    \"\"\"Download the cifar_10 dataset and then load it into memory.\"\"\"\n",
    "    trans = [torchvision.transforms.ToTensor(),\n",
    "             torchvision.transforms.Normalize(mean=(0.4914, 0.4822, 0.4465),\n",
    "                                  std=(0.2023, 0.1994, 0.2010))\n",
    "            ]\n",
    "    if resize:\n",
    "        trans.insert(0, torchvision.transforms.Resize(resize))\n",
    "    trans = torchvision.transforms.Compose(trans)\n",
    "\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root='./cifar-10_data', train=True, download=True, transform=trans)\n",
    "    test_dataset = torchvision.datasets.CIFAR10(root='./cifar-10_data', train=False, download=True, transform=trans)\n",
    "\n",
    "    return (torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, num_workers=2, pin_memory=True), # Using pinned memory\n",
    "            torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=False, num_workers=2, pin_memory=True)) # Using pinned memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d0f07d7-ba30-4fcd-9121-ba61a57333e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128 # Defines the batch size\n",
    "train_iter, test_iter = load_data_cifar_10(batch_size, resize=(32, 32)) # Loads the CIFAR-10 dataset. `train_iter` and `test_iter` are `DataLoader` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "057823cb-6738-4b13-886b-f22786bd261f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(train_iter)) # Requests the first training batch\n",
    "print(X.size()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "236a63a7-6731-4958-8421-7de0804474a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stem is the model's entry point, transforming a raw image (e.g., 32x32x3) into a richer feature map.\n",
    "class Stem(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=64):\n",
    "        super(Stem, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82b7477d-4403-4f49-87ba-a164f9169bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Block flows: Spatial average pooling → FC1 → Activation → FC2 → Softmax\n",
    "# and then, K convolutional branches weighted by output from expert branch.\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, K=4, r=4):\n",
    "        super(Block, self).__init__()\n",
    "        self.K = K\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "            for _ in range(K)\n",
    "        ])\n",
    "\n",
    "        self.fc1 = nn.Linear(in_channels, in_channels // r)\n",
    "        self.fc2 = nn.Linear(in_channels // r, K)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, C, H, W = x.size()\n",
    "\n",
    "        # Expert branch\n",
    "        pooled = F.adaptive_avg_pool2d(x, 1).view(batch_size, C)\n",
    "        a = self.fc1(pooled)\n",
    "        a = F.relu(a)\n",
    "        a = self.fc2(a)\n",
    "        a = self.softmax(a)  # shape: [B, K]\n",
    "\n",
    "        # Convolutional branch\n",
    "        outputs = [conv(x) for conv in self.conv_layers]  # list of tensors [B, C, H, W]\n",
    "        output = sum(a[:, i].view(batch_size, 1, 1, 1) * outputs[i] for i in range(self.K))\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4a80361-92bd-4850-a78c-20cb1f01330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Classifier turns the 2D feature maps to 1D logits.\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes=10):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)  # Global spatial average\n",
    "        self.fc = nn.Linear(in_channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(x)           # shape: (B, C, 1, 1)\n",
    "        x = x.view(x.size(0), -1)  # shape: (B, C)\n",
    "        logits = self.fc(x)        # shape: (B, num_classes)\n",
    "        return logits  # softmax will be applied in loss (e.g., CrossEntropyLoss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2830fa30-279f-4920-807c-99697bc582e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the CNN flows: Stem → Block1 → Block2 → ... → Classifier\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, stem_channels=64, num_blocks=3, block_out_channels=64, K=4):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.stem = Stem(3, stem_channels)\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for _ in range(num_blocks):\n",
    "            block = Block(stem_channels, block_out_channels, K=K)\n",
    "            self.blocks.append(block)\n",
    "\n",
    "        self.classifier = Classifier(block_out_channels, num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bee7edf6-0e0e-4b19-878f-1123b14b29aa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CustomCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "624b7c92-bf6d-4574-b4f7-974f21a0556f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac039bb5-279a-4ff3-9e8a-6f116f188b3e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optimisation algorithm\n",
    "lr = 0.01\n",
    "momentum=0.9\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d2f49f7-392d-4059-9106-4f3cba224fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomCNN(\n",
       "  (stem): Stem(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-2): 3 x Block(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0-3): 4 x Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (fc2): Linear(in_features=16, out_features=4, bias=True)\n",
       "      (softmax): Softmax(dim=1)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applies Xavier initialization\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "755b13f1-c1f4-4a49-a3d9-d4a1ad2f661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct classification\n",
    "def correct(logits, y):\n",
    "    y_hat = logits.argmax(dim=1) # Finds the column with the highest value for each row of `logits`.\n",
    "    return (y_hat == y).float().sum() # Computes the number of times that `y_hat` and `y` match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcc07fb4-d231-4d7a-a7e9-8dfcf99e129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss = 0\n",
    "\n",
    "    with torch.no_grad():  # no gradient calculation\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)  # shape: [B, 10]\n",
    "            loss += criterion(outputs, labels).item()  # Track loss\n",
    "            _, predicted = torch.max(outputs, 1)  # get class with highest score\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return loss / len(dataloader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5607fcc5-d921-41de-aabe-cd9480806b7b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n",
      "Training loss: 0.7000, Training accuracy: 74.72%\n",
      "Testing loss: 0.9830, Testing accuracy: 67.27%\n",
      "Duration: 27.027s\n",
      "\n",
      "Epoch 2/50\n",
      "Training loss: 0.7013, Training accuracy: 74.66%\n",
      "Testing loss: 0.9901, Testing accuracy: 67.13%\n",
      "Duration: 26.384s\n",
      "\n",
      "Epoch 3/50\n",
      "Training loss: 0.6996, Training accuracy: 74.66%\n",
      "Testing loss: 0.9837, Testing accuracy: 67.15%\n",
      "Duration: 27.270s\n",
      "\n",
      "Epoch 4/50\n",
      "Training loss: 0.7018, Training accuracy: 74.69%\n",
      "Testing loss: 0.9860, Testing accuracy: 67.21%\n",
      "Duration: 26.165s\n",
      "\n",
      "Epoch 5/50\n",
      "Training loss: 0.7001, Training accuracy: 74.79%\n",
      "Testing loss: 0.9831, Testing accuracy: 67.12%\n",
      "Duration: 26.835s\n",
      "\n",
      "Epoch 6/50\n",
      "Training loss: 0.6994, Training accuracy: 74.77%\n",
      "Testing loss: 0.9836, Testing accuracy: 67.14%\n",
      "Duration: 25.980s\n",
      "\n",
      "Epoch 7/50\n",
      "Training loss: 0.6996, Training accuracy: 74.68%\n",
      "Testing loss: 0.9833, Testing accuracy: 67.18%\n",
      "Duration: 26.564s\n",
      "\n",
      "Epoch 8/50\n",
      "Training loss: 0.7017, Training accuracy: 74.68%\n",
      "Testing loss: 0.9884, Testing accuracy: 67.25%\n",
      "Duration: 26.419s\n",
      "\n",
      "Epoch 9/50\n",
      "Training loss: 0.6985, Training accuracy: 74.90%\n",
      "Testing loss: 0.9858, Testing accuracy: 67.07%\n",
      "Duration: 26.357s\n",
      "\n",
      "Epoch 10/50\n",
      "Training loss: 0.7012, Training accuracy: 74.79%\n",
      "Testing loss: 0.9878, Testing accuracy: 67.22%\n",
      "Duration: 26.785s\n",
      "\n",
      "Epoch 11/50\n",
      "Training loss: 0.6996, Training accuracy: 74.66%\n",
      "Testing loss: 0.9848, Testing accuracy: 67.30%\n",
      "Duration: 26.375s\n",
      "\n",
      "Epoch 12/50\n",
      "Training loss: 0.6988, Training accuracy: 74.78%\n",
      "Testing loss: 0.9874, Testing accuracy: 67.09%\n",
      "Duration: 26.387s\n",
      "\n",
      "Epoch 13/50\n",
      "Training loss: 0.7000, Training accuracy: 74.75%\n",
      "Testing loss: 0.9831, Testing accuracy: 67.04%\n",
      "Duration: 26.418s\n",
      "\n",
      "Epoch 14/50\n",
      "Training loss: 0.7009, Training accuracy: 74.87%\n",
      "Testing loss: 0.9876, Testing accuracy: 67.11%\n",
      "Duration: 27.316s\n",
      "\n",
      "Epoch 15/50\n",
      "Training loss: 0.7001, Training accuracy: 74.73%\n",
      "Testing loss: 0.9868, Testing accuracy: 67.20%\n",
      "Duration: 26.369s\n",
      "\n",
      "Epoch 16/50\n"
     ]
    }
   ],
   "source": [
    "# Metric tracking\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for X, y in train_iter:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track training loss and accuracy\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total_train += y.size(0)\n",
    "        correct_train += (predicted == y).sum().item()\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        # Store training loss and accuracy\n",
    "        train_losses.append(running_loss / len(train_iter))\n",
    "        train_accs.append(100 * correct_train / total_train)\n",
    "    \n",
    "        # --- Validation ---\n",
    "        test_loss, test_acc = evaluate_model(model, test_iter, device)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accs.append(test_acc)\n",
    "    \n",
    "        # Step the learning rate scheduler\n",
    "        scheduler.step()\n",
    "    \n",
    "        end_time = time.perf_counter()\n",
    "    \n",
    "        # Print epoch details\n",
    "        print(f'Training loss: {train_losses[-1]:.4f}, Training accuracy: {train_accs[-1]:.2f}%')\n",
    "        print(f'Testing loss: {test_losses[-1]:.4f}, Testing accuracy: {test_accs[-1]:.2f}%')\n",
    "        print(f'Duration: {end_time - start_time:.3f}s')\n",
    "\n",
    "final_val_acc = evaluate_model(model, test_iter, device)[1]\n",
    "print(f\"Final validation accuracy: {final_val_acc}%\")\n",
    "\n",
    "# --- Plotting Training Curves ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Loss curves\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss', color='b')\n",
    "plt.plot(test_losses, label='Validation Loss', color='r')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss Evolution')\n",
    "\n",
    "# Plot Accuracy curves\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accs, label='Training Accuracy', color='b')\n",
    "plt.plot(test_accs, label='Validation Accuracy', color='r')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.title('Accuracy Evolution')\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Displaying Hyperparameters ---\n",
    "print(\"\\nTraining Details:\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Learning Rate: {lr}\")\n",
    "print(f\"Momentum: {momentum}\")\n",
    "print(f\"Number of Epochs: {num_epochs}\")\n",
    "print(f\"Optimizer: SGD with momentum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c02a9-64ae-498e-877b-d46aa954646c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d64fa1-dbd2-480d-ada7-3502352124ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d8b787-edfe-449a-9441-2572f0d1d7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
